{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read all files into an array (dataframes)\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "import datetime\n",
    "import re\n",
    "import json\n",
    "directory = os.getcwd() \n",
    "\n",
    "def read_data_from_files(directory):\n",
    "  dataframes= []\n",
    "  for root,dirs,files in os.walk(directory):\n",
    "      for file in files:\n",
    "         if (file.endswith(\"Buildingslogs.csv\") & os.path.exists(file)):\n",
    "            col_names = pd.read_csv(file, nrows=0).columns\n",
    "\n",
    "            dataframes.append(pd.read_csv(file,sep=\";\",low_memory=False,header=[0],skiprows=[1]))\n",
    "  return dataframes\n",
    "\n",
    "\n",
    "#group the data by building where d[str(serial)] = group\n",
    "\n",
    "def group_data_by_building(data):\n",
    "  d = {}\n",
    "  for data in data :\n",
    "    for serial, group in data.groupby('serial'):\n",
    "      d[str(serial)] = group\n",
    "  return d\n",
    "\n",
    "\n",
    "def int_to_time(input,hours_mapping):\n",
    "  return datetime.datetime(2021, 1, 1) + datetime.timedelta(hours=input/hours_mapping)\n",
    "\n",
    "def hour_rounder(t):\n",
    "    # Rounds to nearest hour by adding a timedelta hour if minute >= 30\n",
    "    return (t.replace(second=0, microsecond=0, minute=0, hour=t.hour)\n",
    "               +datetime.timedelta(hours=t.minute//30))  \n",
    "\n",
    "def map_to_real_time(data):\n",
    "  # hou much is an hour in game time \n",
    "  # for example 1hour = 2000 game time unite\n",
    "  res=data\n",
    "  hour_in_numbers = (int(data[0][\"time\"].max()) - int(data[0][\"time\"].min())) / (365*24)\n",
    "  for df in res :\n",
    "    df[\"time\"]=df[\"time\"].apply(int_to_time,args=[hour_in_numbers])\n",
    "    #df[\"time\"]=df[\"time\"].apply(hour_rounder)\n",
    "    df.time=df.time.round(\"0.1S\")\n",
    "  return res  \n",
    "\n",
    "def read_orders_data_from_files(directory):\n",
    "  dataframes= []\n",
    "  for root,dirs,files in os.walk(directory):\n",
    "      for file in files:\n",
    "         if (file.endswith(\"orderslogs.csv\") & os.path.exists(file)):\n",
    "            col_names = pd.read_csv(file, nrows=0).columns\n",
    "\n",
    "            dataframes.append(pd.read_csv(file,sep=\";\",low_memory=False,header=[0],skiprows=[1]))\n",
    "  return dataframes\n",
    "\n",
    "#get one buildings stockes according to IBP Stock\n",
    "#data_line is one line where wares != nan of the original data\n",
    "def data_line_to_one_building_stock_IBP(position):\n",
    "  #locations = pd.DataFrame(columns=['LOCNO','LOCTYPE','NAME1','NAME2','LAND1','REGIO','ORT01','PSTLZ','PSTL2','STRAS','LOEVM','TIME_ZONE','TELF1','FABKL','KUKLA','NODETYPE','CUST_ATTR1','CUST_ATTR2','CUST_ATTR3','CUST_ATTR4','CUST_ATTR5','CUST_ATTR6','CUST_ATTR7','CUST_ATTR8','CUST_ATTR9','CUST_ATTR10','LONGITUDE','LATITUDE'])\n",
    "  #stocks = pd.DataFrame(columns=['MATNR','LOC_WERKS','VRFKZ','MNG01'])\n",
    "  locatins=[\"0\"]*4\n",
    "  locatins[0]=position\n",
    "  locatins[1]=\"V\"\n",
    "  locatins[2]=\"CET\"\n",
    "  locatins[3]=\"03\"\n",
    "  #locations[\"LOCNO\"]=position\n",
    "  #locations[\"LOCTYPE\"]=\"V\"\n",
    "  #locations[\"TIME_ZONE\"]=\"CET\"\n",
    "  #locations[\"FABKL\"]=\"03\"\n",
    "  return locatins\n",
    "  #group_data_by_building\n",
    "\n",
    "def write_series_of_location_to_csv_as_IBPlocation(locationseries_nameseries,filename):\n",
    "\n",
    "  IBPlocations = pd.DataFrame(columns=['MANDT','LOGSYS','LOCID','LOCATIONTYPE','PRODUCTIONCALID','GEOLATITUDE','GEOLONGITUDE','LOCATIONDEL','LOCCITY','LOCCOUNTRY','LOCNAME','LOCNAME2','LOCATIONREGION','LOCTIMEZONE','PHONE','PLANTTYPE','POBOXZIP','STREET','ZIP'])\n",
    "  IBPlocations[[\"LOCID\",\"LOCNAME\"]]=locationseries_nameseries\n",
    "  \n",
    "  #x = set([x[0] for x in test[\"position\"]])\n",
    "  #locations[\"'LATITUDE'\"]=list(x)\n",
    "  IBPlocations[\"MANDT\"]=\"001\"\n",
    "  IBPlocations[\"LOGSYS\"]=\"WDL\"\n",
    "  IBPlocations[\"LOCTYPE\"]=\"P\"\n",
    "  IBPlocations[\"LOCTIMEZONE\"]=\"CET\"\n",
    "  IBPlocations[\"PRODUCTIONCALID\"]=\"03\"\n",
    "  #IBPlocations.drop_duplicates(subset =\"LOCNO\",keep = False, inplace = True)\n",
    "  IBPlocations.to_csv(\"locations\"+filename+ \".csv\",sep=\";\",index=False,header=False)\n",
    "\n",
    "def write_singel_string_wares_attribute_to_csv_as_IBPmaterial(wares):\n",
    "  IBPmaterial = pd.DataFrame(columns=['MANDT','LOGSYS','MATNR','LVORM','MATKL','MEINS','PRDHA','MTART','CUST_ATTR1','CUST_ATTR2','CUST_ATTR3','CUST_ATTR4','CUST_ATTR5','CUST_ATTR6','CUST_ATTR7','CUST_ATTR8','CUST_ATTR9','CUST_ATTR10'])\n",
    "\n",
    "  wares = re.sub(r\".*wares\\:\", \"\", wares)\n",
    "  Dict = json.loads(wares)\n",
    "  wares_amount_data = pd.DataFrame.from_dict(Dict.items())\n",
    "\n",
    "  wares_amount_data.columns = ['ware', 'amount']\n",
    "  IBPmaterial[\"MATNR\"]=wares_amount_data[\"ware\"]\n",
    "  IBPmaterial[\"MEINS\"]=\"piece\"\n",
    "  IBPmaterial[\"MANDT\"]=\"001\"\n",
    "  IBPmaterial[\"LOGSYS\"]=\"WDL\"\n",
    "  IBpmaterialdes = pd.DataFrame(columns=[\"MANDT\",\"LOGSYS\",\"RESID\",\"SPRAS\",\"KTEXT\"])\n",
    "  IBpmaterialdes[\"RESID\"]=IBPmaterial[\"MATNR\"]\n",
    "  IBpmaterialdes[\"SPRAS\"]=\"E\"\n",
    "  IBpmaterialdes[\"MANDT\"]=\"001\"\n",
    "  IBpmaterialdes[\"LOGSYS\"]=\"WDL\"\n",
    "  IBpmaterialdes.to_csv(\"materialsdesc.csv\",sep=\";\",index=False,header=False)\n",
    "  IBPmaterial.to_csv(\"materials.csv\",sep=\";\",index=False,header=False)\n",
    "\n",
    "\n",
    "\n",
    "def write_one_buildings_entry_to_IBPstock(building_entry,filename):\n",
    "  IBPstocks = pd.DataFrame(columns=['MANDT','DELKZ','LOGSYS','MATNR','LOC_WERKS','LGORT','PLAAB','BLANR','LOC_LIFNR','LOC_KUNNR','CHARG','TST01','VRFKZ','MNG01'])\n",
    "  wares=building_entry[\"wares\"]\n",
    "  wares = re.sub(r\".*wares\\:\", \"\", wares)\n",
    "  Dict = json.loads(wares)\n",
    "  wares_amount_data = pd.DataFrame.from_dict(Dict.items())\n",
    "  wares_amount_data.columns = ['ware', 'amount']\n",
    "  IBPstocks[\"MATNR\"]=wares_amount_data[\"ware\"]\n",
    "  IBPstocks[\"MNG01\"]=wares_amount_data[\"amount\"]\n",
    "  IBPstocks['LOC_WERKS']=str(building_entry[\"serial\"])\n",
    "  IBPstocks[\"VRFKZ\"]=\"X\"\n",
    "  IBPstocks['MANDT']=\"001\"\n",
    "  IBPstocks['LOGSYS']=\"WDL\"\n",
    "  IBPstocks.to_csv(filename+\"stocks.csv\",sep=\";\",index=False,header=False)\n",
    "\n",
    "def write_one_buildings_orders_to_IBPorders(orders):\n",
    "  IBPorders = pd.DataFrame(columns=['MANDT','LOGSYS','DELNR','DELPS','DELET','DELKZ','MATNR','LOC_WERKS',\n",
    "  'CHARG','PLAAB','PLANR','LGORT','LOC_LIFNR','LOC_KUNNR','TST01','VRFKZ','MNG01','MNG02',\n",
    "  'MNG03','TST02','FIX01','LOC_WERKS_FROM','VERID','DELVR','AUFVR','POSVR',\n",
    "  'INFNR','EKORG','ESOKZ','MNG04','DEPLOYMENT','MOT_ID','EINVR','DPS_TST','PP_STAGE','REL_FIXED_STATUS'])\n",
    "  IBPorders['MANDT']=\"001\"\n",
    "  IBPorders['LOGSYS']=\"WDL\"\n",
    "  IBPorders['DELNR']=orders.serial.apply(str)+orders.name.apply(str)+orders.time.apply(str)+orders.requested_Ware.apply(str)+orders.amount.apply(str)\n",
    "  IBPorders.to_csv(\"IBPorders.csv\")\n",
    "\n",
    "  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = read_data_from_files(directory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=map_to_real_time(read_data_from_files(directory))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "string=a[0].loc[(a[0]['name'] == \"atlanteans_headquarters\") ][\"wares\"][0]\n",
    "write_singel_string_wares_attribute_to_csv_as_IBPmaterial(a[0].loc[(a[0]['name'] == \"atlanteans_headquarters\") ][\"wares\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_one_buildings_entry_to_IBPstock(a[0].loc[(a[0]['name'] == \"atlanteans_headquarters\") ].iloc[0],str(a[0].loc[(a[0]['name'] == \"atlanteans_headquarters\") ].iloc[0][\"serial\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "string=a[0].loc[(a[0]['name'] == \"atlanteans_headquarters\") ][\"wares\"][0]\n",
    "string = re.sub(r\".*wares\\:\", \"\", string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dict = json.loads(string)\n",
    "fuck = pd.DataFrame.from_dict(Dict.items())\n",
    "fuck.columns = ['ware', 'amount']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0          18763\n",
      "1          18763\n",
      "2          18763\n",
      "3          18763\n",
      "4          18963\n",
      "          ...   \n",
      "7667    14381283\n",
      "7668    14381444\n",
      "7669    14381721\n",
      "7670    14383454\n",
      "7671    14383654\n",
      "Name: time, Length: 7672, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "orders=read_orders_data_from_files(directory)\n",
    "print((orders[0][\"time\"]))\n",
    "orders_maped = map_to_real_time(orders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['serial', 'name', 'time', 'requested_Ware', 'amount'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#print((orders[0][\"time\"]))\n",
    "print(orders_maped[0].columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "orders[0].rename(columns={'building_serial':'serial'}, inplace=True)\n",
    "merged_data = a[0].merge(orders[0], on=[\"serial\",\"time\"], how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['serial', 'name_x', 'time', 'ware_economy_serial',\n",
      "       'worker_economy_serial', 'position', 'reserved_by_worker', 'workers',\n",
      "       'is_mine', 'is_port', 'needs_seafaring', 'needs_water_ways', 'passable',\n",
      "       'is_production_site', 'is_warehouse', 'is_market', 'ware_priorities',\n",
      "       'wares', 'input_queues', 'produced_Wares', 'workinpositions', 'name_y',\n",
      "       'requested_Ware', 'amount'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(merged_data[~merged_data[\"requested_Ware\"].isnull()].columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(data)):\n",
    "  write_series_of_location_to_csv_as_IBPlocation(data[i][[\"serial\",\"name\"]].drop_duplicates(subset=\"serial\"),str(i))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=data[i][[\"serial\",\"name\"]].drop_duplicates(subset=\"serial\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_one_buildings_orders_to_IBPorders(orders[0])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ac2eaa0ea0ebeafcc7822e65e46aa9d4f966f30b695406963e145ea4a91cd4fc"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
